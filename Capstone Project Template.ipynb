{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ETL & Datawarehouse for Traffic Acident Analysis\n",
    "\n",
    "## Project Summary\n",
    "The project will walk through an ETL process for bring together US traffic accidents, COVID cases and city population data from different sources and formats.  The goal will be to analyze how COVID cases in 2020 and population density affects traffic accident volumes in the US.\n",
    "\n",
    "**The project follows the follow steps:**\n",
    "* Step 1: Scope the Project and Gather Data\n",
    "* Step 2: Explore and Assess the Data\n",
    "* Step 3: Define the Data Model\n",
    "* Step 4: Run ETL to Model the Data\n",
    "* Step 5: Complete Project Write Up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Scope the Project and Gather Data\n",
    "\n",
    "**Scope & Data**  \n",
    "Data will be loaded directly from s3 to Redshift. This will help avoid setting-up a server that requires large amounts of storage. Redshidt will be leveraged as the Datawarehouse that will allow for storing and querying large amounts of data leverging distributed computing and parallel processing.\n",
    "\n",
    "The following sources will be used for the data:\n",
    "\n",
    "- **[4.2 Million Traffic accidents](https://www.kaggle.com/sobhanmoosavi/us-accidents)**\n",
    "    - This is a countrywide car accident dataset from Kaggle, which covers 49 states of the USA. The accident data are collected from February 2016 to Dec 2020. There are about 4.2 million accident records in this dataset in CSV format.\n",
    "    - A description of each field is documented here: https://smoosavi.org/datasets/us_accidents\n",
    "    - Moosavi, Sobhan, Mohammad Hossein Samavatian, Srinivasan Parthasarathy, and Rajiv Ramnath. “A Countrywide Traffic Accident Dataset.”, 2019.\n",
    "    - Moosavi, Sobhan, Mohammad Hossein Samavatian, Srinivasan Parthasarathy, Radu Teodorescu, and Rajiv Ramnath. \"Accident Risk Prediction based on Heterogeneous Sparse Data: New Dataset and Insights.\" In proceedings of the 27th ACM SIGSPATIAL International Conference on Advances in Geographic Information Systems, ACM, 2019.\n",
    "- **[City data](https://public.opendatasoft.com/explore/dataset/us-cities-demographics/table/)**\n",
    "    - Includes US city demographic data stored in JSON format from Opendatasoft\n",
    "- **[US covid cases](https://ourworldindata.org/covid-cases?country=~USA)**\n",
    "    - A dataset from ourworldindata.org that includes information about daily COVID cases for the US and other countries\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Explore and Assess the Data\n",
    "We will load the above 3 data sets to review the different columns they provide to define the table schemas, and check if any cleaning steps are required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Traffic accident data exploration and cleaning\n",
    "We load a partial number rows to view the columns and data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Source</th>\n",
       "      <th>TMC</th>\n",
       "      <th>Severity</th>\n",
       "      <th>Start_Time</th>\n",
       "      <th>End_Time</th>\n",
       "      <th>Start_Lat</th>\n",
       "      <th>Start_Lng</th>\n",
       "      <th>End_Lat</th>\n",
       "      <th>End_Lng</th>\n",
       "      <th>Distance(mi)</th>\n",
       "      <th>Description</th>\n",
       "      <th>Number</th>\n",
       "      <th>Street</th>\n",
       "      <th>Side</th>\n",
       "      <th>City</th>\n",
       "      <th>County</th>\n",
       "      <th>State</th>\n",
       "      <th>Zipcode</th>\n",
       "      <th>Country</th>\n",
       "      <th>Timezone</th>\n",
       "      <th>Airport_Code</th>\n",
       "      <th>Weather_Timestamp</th>\n",
       "      <th>Temperature(F)</th>\n",
       "      <th>Wind_Chill(F)</th>\n",
       "      <th>Humidity(%)</th>\n",
       "      <th>Pressure(in)</th>\n",
       "      <th>Visibility(mi)</th>\n",
       "      <th>Wind_Direction</th>\n",
       "      <th>Wind_Speed(mph)</th>\n",
       "      <th>Precipitation(in)</th>\n",
       "      <th>Weather_Condition</th>\n",
       "      <th>Amenity</th>\n",
       "      <th>Bump</th>\n",
       "      <th>Crossing</th>\n",
       "      <th>Give_Way</th>\n",
       "      <th>Junction</th>\n",
       "      <th>No_Exit</th>\n",
       "      <th>Railway</th>\n",
       "      <th>Roundabout</th>\n",
       "      <th>Station</th>\n",
       "      <th>Stop</th>\n",
       "      <th>Traffic_Calming</th>\n",
       "      <th>Traffic_Signal</th>\n",
       "      <th>Turning_Loop</th>\n",
       "      <th>Sunrise_Sunset</th>\n",
       "      <th>Civil_Twilight</th>\n",
       "      <th>Nautical_Twilight</th>\n",
       "      <th>Astronomical_Twilight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A-1</td>\n",
       "      <td>MapQuest</td>\n",
       "      <td>201.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2016-02-08 05:46:00</td>\n",
       "      <td>2016-02-08 11:00:00</td>\n",
       "      <td>39.865147</td>\n",
       "      <td>-84.058723</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.01</td>\n",
       "      <td>Right lane blocked due to accident on I-70 Eas...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I-70 E</td>\n",
       "      <td>R</td>\n",
       "      <td>Dayton</td>\n",
       "      <td>Montgomery</td>\n",
       "      <td>OH</td>\n",
       "      <td>45424</td>\n",
       "      <td>US</td>\n",
       "      <td>US/Eastern</td>\n",
       "      <td>KFFO</td>\n",
       "      <td>2016-02-08 05:58:00</td>\n",
       "      <td>36.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>91.0</td>\n",
       "      <td>29.68</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Calm</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.02</td>\n",
       "      <td>Light Rain</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Night</td>\n",
       "      <td>Night</td>\n",
       "      <td>Night</td>\n",
       "      <td>Night</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A-2</td>\n",
       "      <td>MapQuest</td>\n",
       "      <td>201.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2016-02-08 06:07:59</td>\n",
       "      <td>2016-02-08 06:37:59</td>\n",
       "      <td>39.928059</td>\n",
       "      <td>-82.831184</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.01</td>\n",
       "      <td>Accident on Brice Rd at Tussing Rd. Expect del...</td>\n",
       "      <td>2584.0</td>\n",
       "      <td>Brice Rd</td>\n",
       "      <td>L</td>\n",
       "      <td>Reynoldsburg</td>\n",
       "      <td>Franklin</td>\n",
       "      <td>OH</td>\n",
       "      <td>43068-3402</td>\n",
       "      <td>US</td>\n",
       "      <td>US/Eastern</td>\n",
       "      <td>KCMH</td>\n",
       "      <td>2016-02-08 05:51:00</td>\n",
       "      <td>37.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100.0</td>\n",
       "      <td>29.65</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Calm</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>Light Rain</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Night</td>\n",
       "      <td>Night</td>\n",
       "      <td>Night</td>\n",
       "      <td>Day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A-3</td>\n",
       "      <td>MapQuest</td>\n",
       "      <td>201.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2016-02-08 06:49:27</td>\n",
       "      <td>2016-02-08 07:19:27</td>\n",
       "      <td>39.063148</td>\n",
       "      <td>-84.032608</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.01</td>\n",
       "      <td>Accident on OH-32 State Route 32 Westbound at ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>State Route 32</td>\n",
       "      <td>R</td>\n",
       "      <td>Williamsburg</td>\n",
       "      <td>Clermont</td>\n",
       "      <td>OH</td>\n",
       "      <td>45176</td>\n",
       "      <td>US</td>\n",
       "      <td>US/Eastern</td>\n",
       "      <td>KI69</td>\n",
       "      <td>2016-02-08 06:56:00</td>\n",
       "      <td>36.0</td>\n",
       "      <td>33.3</td>\n",
       "      <td>100.0</td>\n",
       "      <td>29.67</td>\n",
       "      <td>10.0</td>\n",
       "      <td>SW</td>\n",
       "      <td>3.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Overcast</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>Night</td>\n",
       "      <td>Night</td>\n",
       "      <td>Day</td>\n",
       "      <td>Day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A-4</td>\n",
       "      <td>MapQuest</td>\n",
       "      <td>201.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2016-02-08 07:23:34</td>\n",
       "      <td>2016-02-08 07:53:34</td>\n",
       "      <td>39.747753</td>\n",
       "      <td>-84.205582</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.01</td>\n",
       "      <td>Accident on I-75 Southbound at Exits 52 52B US...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I-75 S</td>\n",
       "      <td>R</td>\n",
       "      <td>Dayton</td>\n",
       "      <td>Montgomery</td>\n",
       "      <td>OH</td>\n",
       "      <td>45417</td>\n",
       "      <td>US</td>\n",
       "      <td>US/Eastern</td>\n",
       "      <td>KDAY</td>\n",
       "      <td>2016-02-08 07:38:00</td>\n",
       "      <td>35.1</td>\n",
       "      <td>31.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>29.64</td>\n",
       "      <td>9.0</td>\n",
       "      <td>SW</td>\n",
       "      <td>4.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mostly Cloudy</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Night</td>\n",
       "      <td>Day</td>\n",
       "      <td>Day</td>\n",
       "      <td>Day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A-5</td>\n",
       "      <td>MapQuest</td>\n",
       "      <td>201.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2016-02-08 07:39:07</td>\n",
       "      <td>2016-02-08 08:09:07</td>\n",
       "      <td>39.627781</td>\n",
       "      <td>-84.188354</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.01</td>\n",
       "      <td>Accident on McEwen Rd at OH-725 Miamisburg Cen...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Miamisburg Centerville Rd</td>\n",
       "      <td>R</td>\n",
       "      <td>Dayton</td>\n",
       "      <td>Montgomery</td>\n",
       "      <td>OH</td>\n",
       "      <td>45459</td>\n",
       "      <td>US</td>\n",
       "      <td>US/Eastern</td>\n",
       "      <td>KMGY</td>\n",
       "      <td>2016-02-08 07:53:00</td>\n",
       "      <td>36.0</td>\n",
       "      <td>33.3</td>\n",
       "      <td>89.0</td>\n",
       "      <td>29.65</td>\n",
       "      <td>6.0</td>\n",
       "      <td>SW</td>\n",
       "      <td>3.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mostly Cloudy</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>Day</td>\n",
       "      <td>Day</td>\n",
       "      <td>Day</td>\n",
       "      <td>Day</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ID    Source    TMC  Severity           Start_Time             End_Time  \\\n",
       "0  A-1  MapQuest  201.0         3  2016-02-08 05:46:00  2016-02-08 11:00:00   \n",
       "1  A-2  MapQuest  201.0         2  2016-02-08 06:07:59  2016-02-08 06:37:59   \n",
       "2  A-3  MapQuest  201.0         2  2016-02-08 06:49:27  2016-02-08 07:19:27   \n",
       "3  A-4  MapQuest  201.0         3  2016-02-08 07:23:34  2016-02-08 07:53:34   \n",
       "4  A-5  MapQuest  201.0         2  2016-02-08 07:39:07  2016-02-08 08:09:07   \n",
       "\n",
       "   Start_Lat  Start_Lng  End_Lat  End_Lng  Distance(mi)  \\\n",
       "0  39.865147 -84.058723      NaN      NaN          0.01   \n",
       "1  39.928059 -82.831184      NaN      NaN          0.01   \n",
       "2  39.063148 -84.032608      NaN      NaN          0.01   \n",
       "3  39.747753 -84.205582      NaN      NaN          0.01   \n",
       "4  39.627781 -84.188354      NaN      NaN          0.01   \n",
       "\n",
       "                                         Description  Number  \\\n",
       "0  Right lane blocked due to accident on I-70 Eas...     NaN   \n",
       "1  Accident on Brice Rd at Tussing Rd. Expect del...  2584.0   \n",
       "2  Accident on OH-32 State Route 32 Westbound at ...     NaN   \n",
       "3  Accident on I-75 Southbound at Exits 52 52B US...     NaN   \n",
       "4  Accident on McEwen Rd at OH-725 Miamisburg Cen...     NaN   \n",
       "\n",
       "                      Street Side          City      County State     Zipcode  \\\n",
       "0                     I-70 E    R        Dayton  Montgomery    OH       45424   \n",
       "1                   Brice Rd    L  Reynoldsburg    Franklin    OH  43068-3402   \n",
       "2             State Route 32    R  Williamsburg    Clermont    OH       45176   \n",
       "3                     I-75 S    R        Dayton  Montgomery    OH       45417   \n",
       "4  Miamisburg Centerville Rd    R        Dayton  Montgomery    OH       45459   \n",
       "\n",
       "  Country    Timezone Airport_Code    Weather_Timestamp  Temperature(F)  \\\n",
       "0      US  US/Eastern         KFFO  2016-02-08 05:58:00            36.9   \n",
       "1      US  US/Eastern         KCMH  2016-02-08 05:51:00            37.9   \n",
       "2      US  US/Eastern         KI69  2016-02-08 06:56:00            36.0   \n",
       "3      US  US/Eastern         KDAY  2016-02-08 07:38:00            35.1   \n",
       "4      US  US/Eastern         KMGY  2016-02-08 07:53:00            36.0   \n",
       "\n",
       "   Wind_Chill(F)  Humidity(%)  Pressure(in)  Visibility(mi) Wind_Direction  \\\n",
       "0            NaN         91.0         29.68            10.0           Calm   \n",
       "1            NaN        100.0         29.65            10.0           Calm   \n",
       "2           33.3        100.0         29.67            10.0             SW   \n",
       "3           31.0         96.0         29.64             9.0             SW   \n",
       "4           33.3         89.0         29.65             6.0             SW   \n",
       "\n",
       "   Wind_Speed(mph)  Precipitation(in) Weather_Condition  Amenity   Bump  \\\n",
       "0              NaN               0.02        Light Rain    False  False   \n",
       "1              NaN               0.00        Light Rain    False  False   \n",
       "2              3.5                NaN          Overcast    False  False   \n",
       "3              4.6                NaN     Mostly Cloudy    False  False   \n",
       "4              3.5                NaN     Mostly Cloudy    False  False   \n",
       "\n",
       "   Crossing  Give_Way  Junction  No_Exit  Railway  Roundabout  Station   Stop  \\\n",
       "0     False     False     False    False    False       False    False  False   \n",
       "1     False     False     False    False    False       False    False  False   \n",
       "2     False     False     False    False    False       False    False  False   \n",
       "3     False     False     False    False    False       False    False  False   \n",
       "4     False     False     False    False    False       False    False  False   \n",
       "\n",
       "   Traffic_Calming  Traffic_Signal  Turning_Loop Sunrise_Sunset  \\\n",
       "0            False           False         False          Night   \n",
       "1            False           False         False          Night   \n",
       "2            False            True         False          Night   \n",
       "3            False           False         False          Night   \n",
       "4            False            True         False            Day   \n",
       "\n",
       "  Civil_Twilight Nautical_Twilight Astronomical_Twilight  \n",
       "0          Night             Night                 Night  \n",
       "1          Night             Night                   Day  \n",
       "2          Night               Day                   Day  \n",
       "3            Day               Day                   Day  \n",
       "4            Day               Day                   Day  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Traffic accidents data\n",
    "accident_df = pd.read_csv('capstone_data/US_Accidents_Dec20.csv', nrows=10)\n",
    "accident_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### City demographic data exploration and cleaning\n",
    "We load the JSON data obtained from Opendatasoft "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datasetid</th>\n",
       "      <th>recordid</th>\n",
       "      <th>fields</th>\n",
       "      <th>record_timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>us-cities-demographics</td>\n",
       "      <td>0074451cff52969855654d21497e9459f1108d8d</td>\n",
       "      <td>{'count': 8791, 'city': 'Wichita', 'number_of_...</td>\n",
       "      <td>1969-12-31T16:00:00-08:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>us-cities-demographics</td>\n",
       "      <td>54b201cac9c7523363eb0cfeadc352a04fe016af</td>\n",
       "      <td>{'count': 22304, 'city': 'Allen', 'number_of_v...</td>\n",
       "      <td>1969-12-31T16:00:00-08:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>us-cities-demographics</td>\n",
       "      <td>9dc3d4a59d7e3e2ad31ec5a6d3bab5fac67ee462</td>\n",
       "      <td>{'count': 8454, 'city': 'Danbury', 'number_of_...</td>\n",
       "      <td>1969-12-31T16:00:00-08:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>us-cities-demographics</td>\n",
       "      <td>630ac8078919e7c8c96b861a336c66af27ffcc88</td>\n",
       "      <td>{'count': 67526, 'city': 'Nashville', 'number_...</td>\n",
       "      <td>1969-12-31T16:00:00-08:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>us-cities-demographics</td>\n",
       "      <td>ae093b0dc0b8b9116176092b731533f5b008c75b</td>\n",
       "      <td>{'count': 11013, 'city': 'Stamford', 'number_o...</td>\n",
       "      <td>1969-12-31T16:00:00-08:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                datasetid                                  recordid  \\\n",
       "0  us-cities-demographics  0074451cff52969855654d21497e9459f1108d8d   \n",
       "1  us-cities-demographics  54b201cac9c7523363eb0cfeadc352a04fe016af   \n",
       "2  us-cities-demographics  9dc3d4a59d7e3e2ad31ec5a6d3bab5fac67ee462   \n",
       "3  us-cities-demographics  630ac8078919e7c8c96b861a336c66af27ffcc88   \n",
       "4  us-cities-demographics  ae093b0dc0b8b9116176092b731533f5b008c75b   \n",
       "\n",
       "                                              fields  \\\n",
       "0  {'count': 8791, 'city': 'Wichita', 'number_of_...   \n",
       "1  {'count': 22304, 'city': 'Allen', 'number_of_v...   \n",
       "2  {'count': 8454, 'city': 'Danbury', 'number_of_...   \n",
       "3  {'count': 67526, 'city': 'Nashville', 'number_...   \n",
       "4  {'count': 11013, 'city': 'Stamford', 'number_o...   \n",
       "\n",
       "            record_timestamp  \n",
       "0  1969-12-31T16:00:00-08:00  \n",
       "1  1969-12-31T16:00:00-08:00  \n",
       "2  1969-12-31T16:00:00-08:00  \n",
       "3  1969-12-31T16:00:00-08:00  \n",
       "4  1969-12-31T16:00:00-08:00  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# City demographic data\n",
    "import json \n",
    "  \n",
    "# Opening JSON file \n",
    "f = open('capstone_data/us-cities-demographics.json') \n",
    "\n",
    "data = json.load(f)\n",
    "f.close()\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check the number of rows in the JSON file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2891"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cleaning the data by extracting the `fields` column and writing to a CSV file format**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['count',\n",
       " 'city',\n",
       " 'number_of_veterans',\n",
       " 'male_population',\n",
       " 'foreign_born',\n",
       " 'average_household_size',\n",
       " 'median_age',\n",
       " 'state',\n",
       " 'race',\n",
       " 'total_population',\n",
       " 'state_code',\n",
       " 'female_population']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dct_arr = []\n",
    "for el in df['fields']:\n",
    "    dct_arr.append(el)\n",
    "    \n",
    "labels = []\n",
    "for key in dct_arr[0]:\n",
    "    labels.append(key)\n",
    "\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "try:\n",
    "    with open('capstone_data/cleaned-us-cities-demographics.csv', 'w') as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=labels)\n",
    "        writer.writeheader()\n",
    "        for elem in dct_arr:\n",
    "            writer.writerow(elem)\n",
    "except IOError:\n",
    "    print(\"I/O error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>city</th>\n",
       "      <th>number_of_veterans</th>\n",
       "      <th>male_population</th>\n",
       "      <th>foreign_born</th>\n",
       "      <th>average_household_size</th>\n",
       "      <th>median_age</th>\n",
       "      <th>state</th>\n",
       "      <th>race</th>\n",
       "      <th>total_population</th>\n",
       "      <th>state_code</th>\n",
       "      <th>female_population</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8791</td>\n",
       "      <td>Wichita</td>\n",
       "      <td>23978.0</td>\n",
       "      <td>192354.0</td>\n",
       "      <td>40270.0</td>\n",
       "      <td>2.56</td>\n",
       "      <td>34.6</td>\n",
       "      <td>Kansas</td>\n",
       "      <td>American Indian and Alaska Native</td>\n",
       "      <td>389955</td>\n",
       "      <td>KS</td>\n",
       "      <td>197601.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22304</td>\n",
       "      <td>Allen</td>\n",
       "      <td>5691.0</td>\n",
       "      <td>60626.0</td>\n",
       "      <td>19652.0</td>\n",
       "      <td>2.67</td>\n",
       "      <td>33.5</td>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>Black or African-American</td>\n",
       "      <td>120207</td>\n",
       "      <td>PA</td>\n",
       "      <td>59581.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8454</td>\n",
       "      <td>Danbury</td>\n",
       "      <td>3752.0</td>\n",
       "      <td>43435.0</td>\n",
       "      <td>25675.0</td>\n",
       "      <td>2.74</td>\n",
       "      <td>37.3</td>\n",
       "      <td>Connecticut</td>\n",
       "      <td>Black or African-American</td>\n",
       "      <td>84662</td>\n",
       "      <td>CT</td>\n",
       "      <td>41227.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>67526</td>\n",
       "      <td>Nashville</td>\n",
       "      <td>27942.0</td>\n",
       "      <td>314231.0</td>\n",
       "      <td>88193.0</td>\n",
       "      <td>2.39</td>\n",
       "      <td>34.1</td>\n",
       "      <td>Tennessee</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>654596</td>\n",
       "      <td>TN</td>\n",
       "      <td>340365.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11013</td>\n",
       "      <td>Stamford</td>\n",
       "      <td>2269.0</td>\n",
       "      <td>64941.0</td>\n",
       "      <td>44003.0</td>\n",
       "      <td>2.70</td>\n",
       "      <td>35.4</td>\n",
       "      <td>Connecticut</td>\n",
       "      <td>Asian</td>\n",
       "      <td>128877</td>\n",
       "      <td>CT</td>\n",
       "      <td>63936.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   count       city  number_of_veterans  male_population  foreign_born  \\\n",
       "0   8791    Wichita             23978.0         192354.0       40270.0   \n",
       "1  22304      Allen              5691.0          60626.0       19652.0   \n",
       "2   8454    Danbury              3752.0          43435.0       25675.0   \n",
       "3  67526  Nashville             27942.0         314231.0       88193.0   \n",
       "4  11013   Stamford              2269.0          64941.0       44003.0   \n",
       "\n",
       "   average_household_size  median_age         state  \\\n",
       "0                    2.56        34.6        Kansas   \n",
       "1                    2.67        33.5  Pennsylvania   \n",
       "2                    2.74        37.3   Connecticut   \n",
       "3                    2.39        34.1     Tennessee   \n",
       "4                    2.70        35.4   Connecticut   \n",
       "\n",
       "                                race  total_population state_code  \\\n",
       "0  American Indian and Alaska Native            389955         KS   \n",
       "1          Black or African-American            120207         PA   \n",
       "2          Black or African-American             84662         CT   \n",
       "3                 Hispanic or Latino            654596         TN   \n",
       "4                              Asian            128877         CT   \n",
       "\n",
       "   female_population  \n",
       "0           197601.0  \n",
       "1            59581.0  \n",
       "2            41227.0  \n",
       "3           340365.0  \n",
       "4            63936.0  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "city_df = pd.read_csv('capstone_data/cleaned-us-cities-demographics.csv')\n",
    "city_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### COVID data exploration and cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country name</th>\n",
       "      <th>Code</th>\n",
       "      <th>Day</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Population</th>\n",
       "      <th>Population density (people per km²)</th>\n",
       "      <th>Unnamed: 6</th>\n",
       "      <th>Unnamed: 7</th>\n",
       "      <th>Unnamed: 8</th>\n",
       "      <th>Unnamed: 9</th>\n",
       "      <th>Unnamed: 10</th>\n",
       "      <th>Unnamed: 11</th>\n",
       "      <th>Unnamed: 12</th>\n",
       "      <th>Unnamed: 13</th>\n",
       "      <th>Unnamed: 14</th>\n",
       "      <th>Unnamed: 15</th>\n",
       "      <th>Unnamed: 16</th>\n",
       "      <th>Unnamed: 17</th>\n",
       "      <th>Unnamed: 18</th>\n",
       "      <th>Unnamed: 19</th>\n",
       "      <th>Median age</th>\n",
       "      <th>Share aged 65+</th>\n",
       "      <th>Share aged 70+</th>\n",
       "      <th>GDP per capita (int.-$)</th>\n",
       "      <th>Population in extreme poverty</th>\n",
       "      <th>Human Development Index</th>\n",
       "      <th>Hospital beds (per 1000)</th>\n",
       "      <th>Stringency Index</th>\n",
       "      <th>Life expectancy</th>\n",
       "      <th>Unnamed: 29</th>\n",
       "      <th>Total vaccinations</th>\n",
       "      <th>Total vaccinations (per 100)</th>\n",
       "      <th>New vaccinations</th>\n",
       "      <th>New vaccinations.1</th>\n",
       "      <th>New vaccinations (per 100)</th>\n",
       "      <th>Total deaths</th>\n",
       "      <th>Total deaths (per 1M)</th>\n",
       "      <th>New deaths</th>\n",
       "      <th>New deaths.1</th>\n",
       "      <th>New deaths (per 1M)</th>\n",
       "      <th>New deaths (per 1M).1</th>\n",
       "      <th>New deaths.2</th>\n",
       "      <th>New deaths.3</th>\n",
       "      <th>New deaths (per 1M).2</th>\n",
       "      <th>New deaths (per 1M).3</th>\n",
       "      <th>Total cases</th>\n",
       "      <th>Total cases (per 1M)</th>\n",
       "      <th>New cases</th>\n",
       "      <th>New cases.1</th>\n",
       "      <th>New cases (per 1M)</th>\n",
       "      <th>New cases (per 1M).1</th>\n",
       "      <th>Daily new confirmed COVID-19 cases</th>\n",
       "      <th>Daily new confirmed COVID-19 cases.1</th>\n",
       "      <th>New cases (per 1M).2</th>\n",
       "      <th>New cases (per 1M).3</th>\n",
       "      <th>Daily new COVID-19 tests</th>\n",
       "      <th>Daily new COVID-19 tests per 1,000 people</th>\n",
       "      <th>Total tests</th>\n",
       "      <th>Total tests (per 1K)</th>\n",
       "      <th>Daily new COVID-19 tests.1</th>\n",
       "      <th>Daily new COVID-19 tests.2</th>\n",
       "      <th>Tests per case</th>\n",
       "      <th>Positive test rate</th>\n",
       "      <th>Tests conducted per confirmed case of COVID-19</th>\n",
       "      <th>Positive test rate.1</th>\n",
       "      <th>Unnamed: 65</th>\n",
       "      <th>Case fatality rate</th>\n",
       "      <th>Days since the 5th total confirmed death</th>\n",
       "      <th>Days since 5 daily new deaths first reported</th>\n",
       "      <th>Days since total confirmed deaths reached 0.1 per million</th>\n",
       "      <th>Days since the 100th confirmed case</th>\n",
       "      <th>Days since confirmed cases first reached 30 per day</th>\n",
       "      <th>Days since the total confirmed cases per million people reached 1</th>\n",
       "      <th>Unnamed: 73</th>\n",
       "      <th>Unnamed: 74</th>\n",
       "      <th>Unnamed: 75</th>\n",
       "      <th>Unnamed: 76</th>\n",
       "      <th>Weekly confirmed COVID-19 cases</th>\n",
       "      <th>Biweekly confirmed COVID-19 cases</th>\n",
       "      <th>Weekly confirmed COVID-19 deaths</th>\n",
       "      <th>Biweekly confirmed COVID-19 deaths</th>\n",
       "      <th>Week by week change of confirmed COVID-19 cases</th>\n",
       "      <th>Biweekly change of confirmed COVID-19 cases</th>\n",
       "      <th>Week by week change of confirmed COVID-19 deaths</th>\n",
       "      <th>Biweekly change of confirmed COVID-19 deaths</th>\n",
       "      <th>The share of COVID-19 tests that are positive</th>\n",
       "      <th>Cumulative tests conducted per confirmed case of COVID-19</th>\n",
       "      <th>Cumulative tests conducted per confirmed case of COVID-20</th>\n",
       "      <th>Tests per case.1</th>\n",
       "      <th>Positive test rate.2</th>\n",
       "      <th>Positive test rate.3</th>\n",
       "      <th>Tests per case.2</th>\n",
       "      <th>reproduction_rate</th>\n",
       "      <th>people_vaccinated</th>\n",
       "      <th>people_fully_vaccinated</th>\n",
       "      <th>people_vaccinated_per_hundred</th>\n",
       "      <th>people_fully_vaccinated_per_hundred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>AFG</td>\n",
       "      <td>2020-02-24</td>\n",
       "      <td>Asia</td>\n",
       "      <td>38928341.0</td>\n",
       "      <td>54.422</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>597.029</td>\n",
       "      <td>9.59</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37.746</td>\n",
       "      <td>18.6</td>\n",
       "      <td>2.581</td>\n",
       "      <td>1.337</td>\n",
       "      <td>1803.987</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.511</td>\n",
       "      <td>0.5</td>\n",
       "      <td>8.33</td>\n",
       "      <td>64.83</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.026</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.026</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>AFG</td>\n",
       "      <td>2020-02-25</td>\n",
       "      <td>Asia</td>\n",
       "      <td>38928341.0</td>\n",
       "      <td>54.422</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>597.029</td>\n",
       "      <td>9.59</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37.746</td>\n",
       "      <td>18.6</td>\n",
       "      <td>2.581</td>\n",
       "      <td>1.337</td>\n",
       "      <td>1803.987</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.511</td>\n",
       "      <td>0.5</td>\n",
       "      <td>8.33</td>\n",
       "      <td>64.83</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>AFG</td>\n",
       "      <td>2020-02-26</td>\n",
       "      <td>Asia</td>\n",
       "      <td>38928341.0</td>\n",
       "      <td>54.422</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>597.029</td>\n",
       "      <td>9.59</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37.746</td>\n",
       "      <td>18.6</td>\n",
       "      <td>2.581</td>\n",
       "      <td>1.337</td>\n",
       "      <td>1803.987</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.511</td>\n",
       "      <td>0.5</td>\n",
       "      <td>8.33</td>\n",
       "      <td>64.83</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>AFG</td>\n",
       "      <td>2020-02-27</td>\n",
       "      <td>Asia</td>\n",
       "      <td>38928341.0</td>\n",
       "      <td>54.422</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>597.029</td>\n",
       "      <td>9.59</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37.746</td>\n",
       "      <td>18.6</td>\n",
       "      <td>2.581</td>\n",
       "      <td>1.337</td>\n",
       "      <td>1803.987</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.511</td>\n",
       "      <td>0.5</td>\n",
       "      <td>8.33</td>\n",
       "      <td>64.83</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.750000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>AFG</td>\n",
       "      <td>2020-02-28</td>\n",
       "      <td>Asia</td>\n",
       "      <td>38928341.0</td>\n",
       "      <td>54.422</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>597.029</td>\n",
       "      <td>9.59</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37.746</td>\n",
       "      <td>18.6</td>\n",
       "      <td>2.581</td>\n",
       "      <td>1.337</td>\n",
       "      <td>1803.987</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.511</td>\n",
       "      <td>0.5</td>\n",
       "      <td>8.33</td>\n",
       "      <td>64.83</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.400000</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Country name Code         Day Unnamed: 3  Population  \\\n",
       "0  Afghanistan  AFG  2020-02-24       Asia  38928341.0   \n",
       "1  Afghanistan  AFG  2020-02-25       Asia  38928341.0   \n",
       "2  Afghanistan  AFG  2020-02-26       Asia  38928341.0   \n",
       "3  Afghanistan  AFG  2020-02-27       Asia  38928341.0   \n",
       "4  Afghanistan  AFG  2020-02-28       Asia  38928341.0   \n",
       "\n",
       "   Population density (people per km²)  Unnamed: 6  Unnamed: 7  Unnamed: 8  \\\n",
       "0                               54.422         NaN         NaN         NaN   \n",
       "1                               54.422         NaN         NaN         NaN   \n",
       "2                               54.422         NaN         NaN         NaN   \n",
       "3                               54.422         NaN         NaN         NaN   \n",
       "4                               54.422         NaN         NaN         NaN   \n",
       "\n",
       "   Unnamed: 9  Unnamed: 10  Unnamed: 11  Unnamed: 12  Unnamed: 13 Unnamed: 14  \\\n",
       "0         NaN          NaN          NaN          NaN          NaN         NaN   \n",
       "1         NaN          NaN          NaN          NaN          NaN         NaN   \n",
       "2         NaN          NaN          NaN          NaN          NaN         NaN   \n",
       "3         NaN          NaN          NaN          NaN          NaN         NaN   \n",
       "4         NaN          NaN          NaN          NaN          NaN         NaN   \n",
       "\n",
       "   Unnamed: 15  Unnamed: 16  Unnamed: 17  Unnamed: 18  Unnamed: 19  \\\n",
       "0      597.029         9.59          NaN          NaN       37.746   \n",
       "1      597.029         9.59          NaN          NaN       37.746   \n",
       "2      597.029         9.59          NaN          NaN       37.746   \n",
       "3      597.029         9.59          NaN          NaN       37.746   \n",
       "4      597.029         9.59          NaN          NaN       37.746   \n",
       "\n",
       "   Median age  Share aged 65+  Share aged 70+  GDP per capita (int.-$)  \\\n",
       "0        18.6           2.581           1.337                 1803.987   \n",
       "1        18.6           2.581           1.337                 1803.987   \n",
       "2        18.6           2.581           1.337                 1803.987   \n",
       "3        18.6           2.581           1.337                 1803.987   \n",
       "4        18.6           2.581           1.337                 1803.987   \n",
       "\n",
       "   Population in extreme poverty  Human Development Index  \\\n",
       "0                            NaN                    0.511   \n",
       "1                            NaN                    0.511   \n",
       "2                            NaN                    0.511   \n",
       "3                            NaN                    0.511   \n",
       "4                            NaN                    0.511   \n",
       "\n",
       "   Hospital beds (per 1000)  Stringency Index  Life expectancy  Unnamed: 29  \\\n",
       "0                       0.5              8.33            64.83          NaN   \n",
       "1                       0.5              8.33            64.83          NaN   \n",
       "2                       0.5              8.33            64.83          NaN   \n",
       "3                       0.5              8.33            64.83          NaN   \n",
       "4                       0.5              8.33            64.83          NaN   \n",
       "\n",
       "   Total vaccinations  Total vaccinations (per 100)  New vaccinations  \\\n",
       "0                 NaN                           NaN               NaN   \n",
       "1                 NaN                           NaN               NaN   \n",
       "2                 NaN                           NaN               NaN   \n",
       "3                 NaN                           NaN               NaN   \n",
       "4                 NaN                           NaN               NaN   \n",
       "\n",
       "   New vaccinations.1  New vaccinations (per 100)  Total deaths  \\\n",
       "0                 NaN                         NaN           NaN   \n",
       "1                 NaN                         NaN           NaN   \n",
       "2                 NaN                         NaN           NaN   \n",
       "3                 NaN                         NaN           NaN   \n",
       "4                 NaN                         NaN           NaN   \n",
       "\n",
       "   Total deaths (per 1M)  New deaths  New deaths.1  New deaths (per 1M)  \\\n",
       "0                    NaN         NaN           NaN                  NaN   \n",
       "1                    NaN         NaN           NaN                  NaN   \n",
       "2                    NaN         NaN           NaN                  NaN   \n",
       "3                    NaN         NaN           NaN                  NaN   \n",
       "4                    NaN         NaN           NaN                  NaN   \n",
       "\n",
       "   New deaths (per 1M).1  New deaths.2  New deaths.3  New deaths (per 1M).2  \\\n",
       "0                    NaN           NaN           NaN                    NaN   \n",
       "1                    NaN           NaN           NaN                    NaN   \n",
       "2                    NaN           NaN           NaN                    NaN   \n",
       "3                    NaN           NaN           NaN                    NaN   \n",
       "4                    NaN           NaN           NaN                    NaN   \n",
       "\n",
       "   New deaths (per 1M).3  Total cases  Total cases (per 1M)  New cases  \\\n",
       "0                    NaN          1.0                 0.026        1.0   \n",
       "1                    NaN          1.0                 0.026        0.0   \n",
       "2                    NaN          1.0                 0.026        0.0   \n",
       "3                    NaN          1.0                 0.026        0.0   \n",
       "4                    NaN          1.0                 0.026        0.0   \n",
       "\n",
       "   New cases.1  New cases (per 1M)  New cases (per 1M).1  \\\n",
       "0          1.0               0.026                 0.026   \n",
       "1          0.0               0.000                 0.000   \n",
       "2          0.0               0.000                 0.000   \n",
       "3          0.0               0.000                 0.000   \n",
       "4          0.0               0.000                 0.000   \n",
       "\n",
       "   Daily new confirmed COVID-19 cases  Daily new confirmed COVID-19 cases.1  \\\n",
       "0                                 NaN                                   NaN   \n",
       "1                                 NaN                                   NaN   \n",
       "2                                 NaN                                   NaN   \n",
       "3                                 NaN                                   NaN   \n",
       "4                                 NaN                                   NaN   \n",
       "\n",
       "   New cases (per 1M).2  New cases (per 1M).3  Daily new COVID-19 tests  \\\n",
       "0                   NaN                   NaN                       NaN   \n",
       "1                   NaN                   NaN                       NaN   \n",
       "2                   NaN                   NaN                       NaN   \n",
       "3                   NaN                   NaN                       NaN   \n",
       "4                   NaN                   NaN                       NaN   \n",
       "\n",
       "   Daily new COVID-19 tests per 1,000 people  Total tests  \\\n",
       "0                                        NaN          NaN   \n",
       "1                                        NaN          NaN   \n",
       "2                                        NaN          NaN   \n",
       "3                                        NaN          NaN   \n",
       "4                                        NaN          NaN   \n",
       "\n",
       "   Total tests (per 1K)  Daily new COVID-19 tests.1  \\\n",
       "0                   NaN                         NaN   \n",
       "1                   NaN                         NaN   \n",
       "2                   NaN                         NaN   \n",
       "3                   NaN                         NaN   \n",
       "4                   NaN                         NaN   \n",
       "\n",
       "   Daily new COVID-19 tests.2  Tests per case  Positive test rate  \\\n",
       "0                         NaN             NaN                 NaN   \n",
       "1                         NaN             NaN                 NaN   \n",
       "2                         NaN             NaN                 NaN   \n",
       "3                         NaN             NaN                 NaN   \n",
       "4                         NaN             NaN                 NaN   \n",
       "\n",
       "   Tests conducted per confirmed case of COVID-19  Positive test rate.1  \\\n",
       "0                                             NaN                   NaN   \n",
       "1                                             NaN                   NaN   \n",
       "2                                             NaN                   NaN   \n",
       "3                                             NaN                   NaN   \n",
       "4                                             NaN                   NaN   \n",
       "\n",
       "   Unnamed: 65  Case fatality rate  Days since the 5th total confirmed death  \\\n",
       "0          NaN                 NaN                                       NaN   \n",
       "1          NaN                 NaN                                       NaN   \n",
       "2          NaN                 NaN                                       NaN   \n",
       "3          NaN                 NaN                                       NaN   \n",
       "4          NaN                 NaN                                       NaN   \n",
       "\n",
       "   Days since 5 daily new deaths first reported  \\\n",
       "0                                           NaN   \n",
       "1                                           NaN   \n",
       "2                                           NaN   \n",
       "3                                           NaN   \n",
       "4                                           NaN   \n",
       "\n",
       "   Days since total confirmed deaths reached 0.1 per million  \\\n",
       "0                                                NaN           \n",
       "1                                                NaN           \n",
       "2                                                NaN           \n",
       "3                                                NaN           \n",
       "4                                                NaN           \n",
       "\n",
       "   Days since the 100th confirmed case  \\\n",
       "0                                  NaN   \n",
       "1                                  NaN   \n",
       "2                                  NaN   \n",
       "3                                  NaN   \n",
       "4                                  NaN   \n",
       "\n",
       "   Days since confirmed cases first reached 30 per day  \\\n",
       "0                                                NaN     \n",
       "1                                                NaN     \n",
       "2                                                NaN     \n",
       "3                                                NaN     \n",
       "4                                                NaN     \n",
       "\n",
       "   Days since the total confirmed cases per million people reached 1  \\\n",
       "0                                                NaN                   \n",
       "1                                                NaN                   \n",
       "2                                                NaN                   \n",
       "3                                                NaN                   \n",
       "4                                                NaN                   \n",
       "\n",
       "   Unnamed: 73  Unnamed: 74  Unnamed: 75  Unnamed: 76  \\\n",
       "0     1.000000     1.000000          NaN          NaN   \n",
       "1     0.500000     0.500000          NaN          NaN   \n",
       "2     0.333333     0.333333          NaN          NaN   \n",
       "3     0.250000     0.250000          NaN          NaN   \n",
       "4     0.200000     0.200000          NaN          NaN   \n",
       "\n",
       "   Weekly confirmed COVID-19 cases  Biweekly confirmed COVID-19 cases  \\\n",
       "0                         7.000000                          14.000000   \n",
       "1                         3.500000                           7.000000   \n",
       "2                         2.333333                           4.666667   \n",
       "3                         1.750000                           3.500000   \n",
       "4                         1.400000                           2.800000   \n",
       "\n",
       "   Weekly confirmed COVID-19 deaths  Biweekly confirmed COVID-19 deaths  \\\n",
       "0                               NaN                                 NaN   \n",
       "1                               NaN                                 NaN   \n",
       "2                               NaN                                 NaN   \n",
       "3                               NaN                                 NaN   \n",
       "4                               NaN                                 NaN   \n",
       "\n",
       "   Week by week change of confirmed COVID-19 cases  \\\n",
       "0                                              NaN   \n",
       "1                                              NaN   \n",
       "2                                              NaN   \n",
       "3                                              NaN   \n",
       "4                                              NaN   \n",
       "\n",
       "   Biweekly change of confirmed COVID-19 cases  \\\n",
       "0                                          NaN   \n",
       "1                                          NaN   \n",
       "2                                          NaN   \n",
       "3                                          NaN   \n",
       "4                                          NaN   \n",
       "\n",
       "   Week by week change of confirmed COVID-19 deaths  \\\n",
       "0                                               NaN   \n",
       "1                                               NaN   \n",
       "2                                               NaN   \n",
       "3                                               NaN   \n",
       "4                                               NaN   \n",
       "\n",
       "   Biweekly change of confirmed COVID-19 deaths  \\\n",
       "0                                           NaN   \n",
       "1                                           NaN   \n",
       "2                                           NaN   \n",
       "3                                           NaN   \n",
       "4                                           NaN   \n",
       "\n",
       "   The share of COVID-19 tests that are positive  \\\n",
       "0                                            NaN   \n",
       "1                                            NaN   \n",
       "2                                            NaN   \n",
       "3                                            NaN   \n",
       "4                                            NaN   \n",
       "\n",
       "   Cumulative tests conducted per confirmed case of COVID-19  \\\n",
       "0                                                NaN           \n",
       "1                                                NaN           \n",
       "2                                                NaN           \n",
       "3                                                NaN           \n",
       "4                                                NaN           \n",
       "\n",
       "   Cumulative tests conducted per confirmed case of COVID-20  \\\n",
       "0                                                NaN           \n",
       "1                                                NaN           \n",
       "2                                                NaN           \n",
       "3                                                NaN           \n",
       "4                                                NaN           \n",
       "\n",
       "   Tests per case.1  Positive test rate.2  Positive test rate.3  \\\n",
       "0               NaN                   NaN                   NaN   \n",
       "1               NaN                   NaN                   NaN   \n",
       "2               NaN                   NaN                   NaN   \n",
       "3               NaN                   NaN                   NaN   \n",
       "4               NaN                   NaN                   NaN   \n",
       "\n",
       "   Tests per case.2  reproduction_rate  people_vaccinated  \\\n",
       "0               NaN                NaN                NaN   \n",
       "1               NaN                NaN                NaN   \n",
       "2               NaN                NaN                NaN   \n",
       "3               NaN                NaN                NaN   \n",
       "4               NaN                NaN                NaN   \n",
       "\n",
       "   people_fully_vaccinated  people_vaccinated_per_hundred  \\\n",
       "0                      NaN                            NaN   \n",
       "1                      NaN                            NaN   \n",
       "2                      NaN                            NaN   \n",
       "3                      NaN                            NaN   \n",
       "4                      NaN                            NaN   \n",
       "\n",
       "   people_fully_vaccinated_per_hundred  \n",
       "0                                  NaN  \n",
       "1                                  NaN  \n",
       "2                                  NaN  \n",
       "3                                  NaN  \n",
       "4                                  NaN  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# COVID case data\n",
    "covid_df = pd.read_csv('capstone_data/coronavirus-data-explorer.csv')\n",
    "covid_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Extract specific columns relevant to load to reduce the size of data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_df = covid_df[['Country name', 'Day', 'Stringency Index', 'Total vaccinations', 'Total deaths', 'Total cases', \n",
    "                     'Daily new confirmed COVID-19 cases', 'Biweekly confirmed COVID-19 cases']]\n",
    "\n",
    "column_dict = {'Country name':'country_name', \n",
    "               'Day':'day',\n",
    "               'Stringency Index':'stringency_index',\n",
    "               'Total vaccinations': 'total_vaccinations',\n",
    "               'Total deaths': 'total_deaths',\n",
    "               'Total cases': 'total_cases',\n",
    "               'Daily new confirmed COVID-19 cases': 'daily_new_cases',\n",
    "               'Biweekly confirmed COVID-19 cases': 'biweekly_cases'}\n",
    "\n",
    "covid_df.rename(columns = column_dict, inplace = True)\n",
    "\n",
    "covid_df.to_csv('capstone_data/cleaned-coronavirus-data-explorer.csv', index=False,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check the row count for COVID data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75071"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "covid_df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check the row count for COVID data specific to the US**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "419"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rslt_df = covid_df.loc[covid_df['country_name'] == 'United States']\n",
    "rslt_df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Define the Data Model\n",
    "\n",
    "### 3.1 Conceptual Data Model\n",
    "\n",
    "The database schema is normalized using a *star schema* and tables are structured in the following format. A star schema reduces data redundancy while also making queries for analytics simple by reducing complex joins. \n",
    "\n",
    "<img src=\"assets/img/schema.png\" alt=\"schema\" width=\"650\" height=\"650\"/>\n",
    "\n",
    "\n",
    "### 3.2 Mapping Out Data Pipelines\n",
    "\n",
    "**The ETL will follow the below steps**\n",
    "1. Create staging and fact/dimension tables in Redshift\n",
    "2. COPY data from S3 into staging tables in Redshift\n",
    "3. Run INSERT INTO statements from staging table to fact/dimension tables\n",
    "\n",
    "\n",
    "**The following scripts and files will be used for ETL**\n",
    "- `dwh.cfg` includes parameters required access AWS resources such as S3 & Redshift.\n",
    "- `sql_queries.py` includes all the ETL related SQL queries.\n",
    "- `create_tables.py` to create the necessary SQL tables.\n",
    "- `etl.py` to load data from S3 to Redshift and transform data in to Star schema."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Run Pipelines to Model the Data \n",
    "\n",
    "### 4.1 Create the data model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Create tables in Redshift by running create_tables.py**  \n",
    "create_table.py includes SQL query statements that will create both staging and fact/dimension tables.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating table \n",
      "    CREATE TABLE IF NOT EXISTS accident_staging_table (\n",
      "        id                      VARCHAR,\n",
      "        source                  VARCHAR,\n",
      "        tmc                     REAL,\n",
      "        severity                INT,\n",
      "        start_time              TIMESTAMP,\n",
      "        end_time                TIMESTAMP,\n",
      "        start_lat               NUMERIC(9,6),\n",
      "        start_lng               NUMERIC(9,6),\n",
      "        end_lat                 NUMERIC(9,6),\n",
      "        end_lng                 NUMERIC(9,6),\n",
      "        distance                REAL,\n",
      "        description             VARCHAR(MAX),\n",
      "        number                  REAL,\n",
      "        street                  VARCHAR,\n",
      "        side                    VARCHAR(1),\n",
      "        city                    VARCHAR,\n",
      "        county                  VARCHAR,\n",
      "        state                   VARCHAR(5),\n",
      "        zipcode                 VARCHAR,\n",
      "        country                 VARCHAR,\n",
      "        timezone                VARCHAR,\n",
      "        airport_code            VARCHAR,\n",
      "        weather_time            TIMESTAMP,\n",
      "        temprature              REAL,\n",
      "        wind_chill              REAL,\n",
      "        humidity                REAL,\n",
      "        pressure                REAL,\n",
      "        visibility              REAL,\n",
      "        wind_direction          VARCHAR,\n",
      "        wind_speed              REAL,\n",
      "        percipiration           REAL,\n",
      "        weather_condition       VARCHAR,\n",
      "        amenity                 BOOLEAN,          \n",
      "        bump                    BOOLEAN,\n",
      "        crossing                BOOLEAN,\n",
      "        give_way                BOOLEAN,\n",
      "        junction                BOOLEAN,\n",
      "        no_exit                 BOOLEAN,\n",
      "        railway                 BOOLEAN,\n",
      "        roundabout              BOOLEAN,\n",
      "        station                 BOOLEAN,\n",
      "        stop                    BOOLEAN,\n",
      "        traffic_calming         BOOLEAN,\n",
      "        traffic_signal          BOOLEAN,\n",
      "        turning_loop            BOOLEAN,\n",
      "        sunrise_sunset          VARCHAR,\n",
      "        civil_twilight          VARCHAR,\n",
      "        nautical_twilight       VARCHAR,\n",
      "        astronomical_twilight   VARCHAR\n",
      "    )\n",
      "\n",
      "Creating table \n",
      "    CREATE TABLE IF NOT EXISTS city_staging_table (\n",
      "        count                  INT,\n",
      "        city                   VARCHAR,\n",
      "        number_of_veterans     INT,\n",
      "        male_population        INT,\n",
      "        foreign_born           INT,\n",
      "        average_household_size REAL,\n",
      "        median_age             REAL,\n",
      "        state                  VARCHAR,\n",
      "        race                   VARCHAR,\n",
      "        total_population       INT,\n",
      "        state_code             VARCHAR,\n",
      "        female_population      INT\n",
      "    )\n",
      "\n",
      "Creating table \n",
      "    CREATE TABLE IF NOT EXISTS covid_staging_table (\n",
      "        country_name        VARCHAR,\n",
      "        day                 TIMESTAMP,\n",
      "        stringency_index    REAL,\n",
      "        total_vaccinations  REAL,\n",
      "        total_deaths        REAL,\n",
      "        total_cases         REAL,\n",
      "        daily_cases         REAL,\n",
      "        biweekly_cases      REAL\n",
      "    )\n",
      "\n",
      "Creating table \n",
      "    CREATE TABLE IF NOT EXISTS time_table(\n",
      "        start_time_key TIMESTAMP PRIMARY KEY,\n",
      "        start_time     TIMESTAMP SORTKEY,\n",
      "        hour           INT,\n",
      "        day            INT,\n",
      "        week           INT,\n",
      "        month          INT,\n",
      "        year           INT,\n",
      "        weekend        BOOLEAN \n",
      "    )DISTSTYLE ALL\n",
      "\n",
      "Creating table \n",
      "    CREATE TABLE IF NOT EXISTS covid_table(\n",
      "        date_key             TIMESTAMP PRIMARY KEY,\n",
      "        total_cases          INT SORTKEY,\n",
      "        total_deaths         INT,\n",
      "        daily_cases          INT,\n",
      "        biweekly_cases       INT,\n",
      "        total_vaccinations   INT        \n",
      "    )DISTSTYLE ALL\n",
      "\n",
      "Creating table \n",
      "    CREATE TABLE IF NOT EXISTS city_table(\n",
      "        city_key                 VARCHAR PRIMARY KEY,\n",
      "        total_population         INT SORTKEY,\n",
      "        average_household_size   REAL,\n",
      "        median_age               INT,\n",
      "        male_population          INT,     \n",
      "        female_population        INT,\n",
      "        state                    VARCHAR\n",
      "    )DISTSTYLE ALL\n",
      "\n",
      "Creating table \n",
      "    CREATE TABLE IF NOT EXISTS accident_table (\n",
      "        accident_id     VARCHAR PRIMARY KEY,\n",
      "        severity        INT,\n",
      "        start_time_key  TIMESTAMP REFERENCES time_table (start_time_key) NOT NULL,\n",
      "        end_time        TIMESTAMP,\n",
      "        date_key        TIMESTAMP REFERENCES covid_table (date_key) NOT NULL, \n",
      "        description     VARCHAR(MAX), \n",
      "        city_key        VARCHAR REFERENCES city_table (city_key) NOT NULL DISTKEY,\n",
      "        temprature      REAL,\n",
      "        wind_chill      REAL,\n",
      "        humidity        REAL,\n",
      "        pressure        REAL,\n",
      "        visibility      REAL,\n",
      "        wind_speed      REAL,\n",
      "        weather_condition  VARCHAR,\n",
      "        sunrise_sunset  VARCHAR\n",
      "    )\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python create_tables.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. COPY data from S3 to staging tables in Redshift**  \n",
    "**3. Run transformations and load from staging to fact/diemenstion tables**  \n",
    "etl.py includes both COPY SQL statements and INSERT INTO statements for loading and transformations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying data from S3:  \n",
      "    COPY covid_staging_table FROM 's3://patrickcapstone/capstone_data/cleaned-coronavirus-data-explorer.csv'\n",
      "    iam_role 'arn:aws:iam::489883123546:role/dwhRole'\n",
      "    CSV\n",
      "    IGNOREHEADER 1\n",
      "    REGION 'us-west-2'\n",
      "\n",
      "Copying data from S3:  \n",
      "    COPY city_staging_table FROM 's3://patrickcapstone/capstone_data/cleaned-us-cities-demographics.csv'\n",
      "    iam_role 'arn:aws:iam::489883123546:role/dwhRole'\n",
      "    CSV\n",
      "    IGNOREHEADER 1\n",
      "    REGION 'us-west-2'\n",
      "\n",
      "Copying data from S3:  \n",
      "    COPY accident_staging_table FROM 's3://patrickcapstone/capstone_data/US_Accidents_Dec20.csv'\n",
      "    iam_role 'arn:aws:iam::489883123546:role/dwhRole'\n",
      "    CSV\n",
      "    IGNOREHEADER 1\n",
      "    REGION 'us-west-2'\n",
      "\n",
      "Transforming data:  \n",
      "    INSERT INTO accident_table (accident_id, severity, start_time_key, end_time, date_key, \n",
      "                                description, city_key, temprature, wind_chill, humidity, \n",
      "                                pressure, visibility, wind_speed, weather_condition, sunrise_sunset)\n",
      "    SELECT id, severity, start_time, end_time, start_time::date as date, \n",
      "           description, city, temprature, wind_chill, humidity, pressure, visibility, wind_speed, \n",
      "           weather_condition, sunrise_sunset\n",
      "    FROM accident_staging_table\n",
      "\n",
      "Transforming data:  \n",
      "    INSERT INTO city_table (city_key, total_population, average_household_size, median_age,\n",
      "                            male_population, female_population, state)\n",
      "    SELECT DISTINCT city, total_population, average_household_size, median_age, \n",
      "                    male_population, female_population, state\n",
      "    FROM city_staging_table\n",
      "\n",
      "Transforming data:  \n",
      "    INSERT INTO covid_table (date_key, total_cases, total_deaths, daily_cases,\n",
      "                             biweekly_cases, total_vaccinations)\n",
      "    SELECT DISTINCT day, total_cases, total_deaths, daily_cases,\n",
      "                    biweekly_cases, total_vaccinations \n",
      "    FROM covid_staging_table\n",
      "    WHERE country_name = 'United States'\n",
      "\n",
      "Transforming data:  \n",
      "    INSERT INTO time_table (start_time_key, start_time, hour, day,\n",
      "                            week, month, year, weekend)\n",
      "    SELECT DISTINCT a.start_time,\n",
      "           a.start_time,\n",
      "           EXTRACT(hour FROM a.start_time),\n",
      "           EXTRACT(day FROM a.start_time),\n",
      "           EXTRACT(week FROM a.start_time),\n",
      "           EXTRACT(month FROM a.start_time),\n",
      "           EXTRACT(year FROM a.start_time),\n",
      "           CASE\n",
      "               WHEN 5 = EXTRACT(weekday FROM a.start_time) THEN True\n",
      "               WHEN 6 = EXTRACT(weekday FROM a.start_time) THEN True\n",
      "               ELSE False\n",
      "           END\n",
      "    FROM (SELECT start_time \n",
      "    FROM accident_staging_table) a;\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python etl.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Data Quality Checks\n",
    "\n",
    "**Defining tables with variables types**  \n",
    "When defining the tables, variables types have been defined and in some cases character lengths have been defined. **Primary Key** has been defined to ensure keys are unique and not `Null`.\n",
    "\n",
    "**Check row count for tables**  \n",
    "Run SQL queries to check row counts to validate data has been loaded properly into staging tables and transformation into fact/dimension tables have been done properly as well.\n",
    "\n",
    "`Select Count(city)\n",
    "From city_staging_table`  \n",
    "Row count should be: 2,891\n",
    "\n",
    "\n",
    "`Select Count(id)\n",
    "From accident_staging_table`  \n",
    "Row count should be: 4,232,541\n",
    "\n",
    "\n",
    "`Select Count(id)\n",
    "From covid_staging_table`  \n",
    "Row count should be: 75,071\n",
    "\n",
    "\n",
    "`Select Count(date_key)\n",
    "From covid_table`   \n",
    "Row count should be: 419\n",
    "\n",
    "\n",
    "`Select Count(start_time_key)\n",
    "From time_table`  \n",
    "Row count should be: 3,634,540\n",
    "\n",
    "\n",
    "`Select Count(accident_id)\n",
    "From accident_table`  \n",
    "Row count should be: 4,232,541\n",
    "\n",
    "\n",
    "`Select Count(city_key)\n",
    "From city_table`  \n",
    "Row count should be: 596\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Data dictionary \n",
    "\n",
    "A data dictionary is located under: data_dictionary/data_dictionary.xlsx\n",
    "\n",
    "<img src=\"assets/data_dictionary/data_dictionary_screenshot.png\" alt=\"dictionary\" width=\"550\" height=\"550\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Project Summary\n",
    "\n",
    "\n",
    "### Rational\n",
    "By extracting and loading data from S3 directly to Redshift, we avoid setting-up a server that requires large amounts of storage. Leveraging a Datawarehouse such as Redshift allows for storing and querying large amounts of data leverging distributed computing and parallel processing. In this case, we can easily query 4.2 million rows of accident data in the US across different cities. \n",
    "\n",
    "The database schema is normalized using a *star schema*. A star schema reduces data redundancy while also optimizing for specific queries.\n",
    "\n",
    "Redshift distribution keys are used to distribute data across nodes in order for queries to scale even with large amounts of data. The largest table, the accident_table is distributed based on the **city_key** column.\n",
    "\n",
    "The data should be updated daily to gather new covid case and accident data that is updated. \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Use Cases\n",
    "With this schema, we can run queries such as how COVID has affected the amount of traffic accidents on a given day. \n",
    "\n",
    "**Query example**\n",
    "```\n",
    "With accidents As \n",
    "\t(Select date_key as date, Count(accident_id) as total_accidents\n",
    "\tFrom accident_table\n",
    "\tGroup By date_key)\n",
    "\n",
    "Select a.date, a.total_accidents, c.biweekly_cases, c.total_cases\n",
    "From covid_table c\n",
    "Join accidents a On a.date = c.date_key\n",
    "```\n",
    "\n",
    "**Visualization of data from Redshift**\n",
    "This seems to show that traffic accidents did not seem to decrease even though covid cases increased. However, it does seem that there are drops in accidents during lockdown periods.\n",
    "<img src=\"assets/img/visualization.png\" alt=\"dictionary\" width=\"550\" height=\"550\"/>\n",
    "\n",
    "\n",
    "### Further Exploration\n",
    "\n",
    "**Large datasets**\n",
    "If larger amounts of data is required to be processed, Redshift nodes can be further scaled-up and scaled out. Another option would be to switch to using Spark to run the ETL pipeline.\n",
    "\n",
    "\n",
    "**Automating/scheduling pipeline**\n",
    "Airflow can be used in order to schedule the ETL process to run on a regular schedule. Setting-up a structured and automated ETL with DAGs will also make the ETL process more reliable. \n",
    "\n",
    "**Concurrent users**\n",
    "If hundreds or thousands of user require access to query the data, Redshift support this with Concurrency Scaling. Spark would also allow for large numbers of concurrent users.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
